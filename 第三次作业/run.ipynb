{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as pil_image\n",
    "from pytorch_msssim import ssim, ms_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SRCNN()\n",
    "model.load_state_dict(torch.load('srcnn_x2.pth', map_location=torch.device('cpu'))) # 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_ycbcr(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        y = 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "        cb = 128. + (-37.945 * img[:, :, 0] - 74.494 * img[:, :, 1] + 112.439 * img[:, :, 2]) / 256.\n",
    "        cr = 128. + (112.439 * img[:, :, 0] - 94.154 * img[:, :, 1] - 18.285 * img[:, :, 2]) / 256.\n",
    "        return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        y = 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
    "        cb = 128. + (-37.945 * img[0, :, :] - 74.494 * img[1, :, :] + 112.439 * img[2, :, :]) / 256.\n",
    "        cr = 128. + (112.439 * img[0, :, :] - 94.154 * img[1, :, :] - 18.285 * img[2, :, :]) / 256.\n",
    "        return torch.cat([y, cb, cr], 0).permute(1, 2, 0)\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "\n",
    "\n",
    "def convert_ycbcr_to_rgb(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        r = 298.082 * img[:, :, 0] / 256. + 408.583 * img[:, :, 2] / 256. - 222.921\n",
    "        g = 298.082 * img[:, :, 0] / 256. - 100.291 * img[:, :, 1] / 256. - 208.120 * img[:, :, 2] / 256. + 135.576\n",
    "        b = 298.082 * img[:, :, 0] / 256. + 516.412 * img[:, :, 1] / 256. - 276.836\n",
    "        return np.array([r, g, b]).transpose([1, 2, 0])\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        r = 298.082 * img[0, :, :] / 256. + 408.583 * img[2, :, :] / 256. - 222.921\n",
    "        g = 298.082 * img[0, :, :] / 256. - 100.291 * img[1, :, :] / 256. - 208.120 * img[2, :, :] / 256. + 135.576\n",
    "        b = 298.082 * img[0, :, :] / 256. + 516.412 * img[1, :, :] / 256. - 276.836\n",
    "        return torch.cat([r, g, b], 0).permute(1, 2, 0)\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "\n",
    "def calc_psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageName: baby, PSNR: 41.20, SSIM: 0.9851\n",
      "ImageName: woman, PSNR: 34.62, SSIM: 0.9753\n",
      "ImageName: head, PSNR: 41.27, SSIM: 0.9776\n",
      "ImageName: bird, PSNR: 38.32, SSIM: 0.9827\n",
      "ImageName: butterfly, PSNR: 29.55, SSIM: 0.9484\n",
      "Mean_PSNR: 36.99, Mean_SSIM: 0.9738\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"../../data/Set5\" # 原图\n",
    "target_dir = \"../../data/Super\" # 重建结果\n",
    "trans_dir = \"../../data/Trans\" # Bicubic采样后结果\n",
    "os.makedirs(trans_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "file_list = os.listdir(source_dir)\n",
    "scale = 2  #下样本率\n",
    "mean_psnr, mean_ssim = 0., 0.\n",
    "for file in file_list:\n",
    "    origin_image_path = os.path.join(source_dir, file)\n",
    "    image = pil_image.open(origin_image_path).convert('RGB')\n",
    "\n",
    "    image_width = (image.width // scale) * scale\n",
    "    image_height = (image.height // scale) * scale\n",
    "    image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "    image = image.resize((image.width // scale, image.height // scale), resample=pil_image.BICUBIC)\n",
    "    image = image.resize((image.width * scale, image.height * scale), resample=pil_image.BICUBIC)\n",
    "    image.save(os.path.join(trans_dir, file))\n",
    "    image = np.array(image).astype(np.float32)\n",
    "    ycbcr = convert_rgb_to_ycbcr(image)\n",
    "\n",
    "    y = ycbcr[..., 0]\n",
    "    y /= 255.\n",
    "    y = torch.from_numpy(y)\n",
    "    y = y.unsqueeze(0).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(y).clamp(0.0, 1.0)\n",
    "    psnr = calc_psnr(y, preds)\n",
    "    ssim_val = ssim( y, preds, data_range=1, size_average=False).item()\n",
    "    mean_psnr += psnr\n",
    "    mean_ssim += ssim_val\n",
    "    print('ImageName: {:s}, PSNR: {:.2f}, SSIM: {:.4f}'.format(file.split(\".\")[0], psnr, ssim_val))\n",
    "\n",
    "    # 保存文件\n",
    "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "    output = pil_image.fromarray(output)\n",
    "    output.save(os.path.join(target_dir, file))\n",
    "\n",
    "print('Mean_PSNR: {:.2f}, Mean_SSIM: {:.4f}'.format(mean_psnr / len(file_list), mean_ssim / len(file_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
